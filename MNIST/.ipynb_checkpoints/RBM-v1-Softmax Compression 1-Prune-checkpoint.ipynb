{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_vis=784,\n",
    "                 n_hin=625,\n",
    "                 k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "    def sample_from_p(self,p):\n",
    "        return F.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "    def v_to_h(self,v):\n",
    "        p_h = F.sigmoid(F.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_from_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "    def h_to_v(self,h):\n",
    "        p_v = F.sigmoid(F.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_from_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "    def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_, h_\n",
    "    \n",
    "    def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = F.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding target at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(train_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "        target=target.view(-1)\n",
    "        target=target.numpy()\n",
    "        target_data.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=np.array(target_data[0])\n",
    "x=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,938):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    x=torch.cat((x, y),0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,938):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=x.numpy()\n",
    "\n",
    "target_array=np.zeros((60000,10))\n",
    "\n",
    "count=0\n",
    "for n in x:\n",
    "    target_array[count][n]=1\n",
    "    count+=1\n",
    "\n",
    "target_array=torch.Tensor(target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_training_data=torch.cat((full_input, target_array), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = RBM(k=5, n_vis=794)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: Variable containing:\n",
      " 0.1178\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-2.07829307467\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  8.6326\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-5.30928220311\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.9327\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-3.39327485075\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.5343\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-2.19898004847\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.2774\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-1.3512001974\n"
     ]
    }
   ],
   "source": [
    "batch_size_=64\n",
    "\n",
    "for epoch in range(5):\n",
    "    loss_ = []\n",
    "    reconstruction_error=0\n",
    "    s=0\n",
    "    for n in range(0, len(final_training_data)- batch_size_, batch_size_):\n",
    "        sample_data=final_training_data[n:n+batch_size_]\n",
    "        sample_data=Variable(sample_data)\n",
    "        sample_data = sample_data.bernoulli()\n",
    "        v,v1,h1 = rbm(sample_data)\n",
    "        \n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data[0])\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        reconstruction_error+=torch.mean(torch.abs(v-v1))\n",
    "        s+=1\n",
    "    print (' loss: ' + str(reconstruction_error/s))     \n",
    "    print (np.mean(loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,157):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dummy=np.zeros((len(full_input), 10))\n",
    "test_dummy=torch.Tensor(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set=torch.cat((full_input, test_dummy), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights=rbm.W\n",
    "weights=weights.data.numpy()\n",
    "\n",
    "\n",
    "x=weights.reshape(496250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savedweights=weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=savedweights.reshape(496250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune\n",
    "i = []\n",
    "\n",
    "for w in x:\n",
    "    if w < 0.1 and w > -0.1:\n",
    "        w=0\n",
    "        \n",
    "    else:\n",
    "        w=w\n",
    "    i.append(w)\n",
    "\n",
    "i=np.array(i).reshape(625, 794)\n",
    "\n",
    "w=torch.Tensor(i)\n",
    "\n",
    "\n",
    "o=torch.nn.Parameter(w)\n",
    "rbm.W=o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantise\n",
    "\n",
    "q=[]\n",
    "\n",
    "for w in x:\n",
    "    if w > 0.15:\n",
    "        w=float(1)\n",
    "    elif w<-0.15:\n",
    "        w=float(-1)\n",
    "    else:\n",
    "        w=float(0)\n",
    "    q.append(w)\n",
    "    \n",
    "q=np.array(q).reshape(625, 794)\n",
    "w=torch.Tensor(q)\n",
    "w=torch.nn.Parameter(w)\n",
    "rbm.W=w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "    0     0     0  ...      0     1    -1\n",
       "    0     0     0  ...      0    -1    -1\n",
       "    0     0     0  ...      1    -1    -1\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0    -1\n",
       "    0     0     0  ...     -1     1    -1\n",
       "    0     0     0  ...     -1    -1     0\n",
       "[torch.FloatTensor of size 625x794]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  8.6283\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output=[]\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "s=0\n",
    "for n in range(0,len(test_set)):\n",
    "    sample_data=Variable(test_set)\n",
    "    sample_data = sample_data[n:n+1]\n",
    "\n",
    "    v,v1,h1 = rbm(sample_data)\n",
    "    test_loss+=torch.mean(torch.abs(v-v1))\n",
    "    s+=1\n",
    "    output.append(v1)\n",
    "print (' loss: ' + str(test_loss/s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "    target=target.view(-1)\n",
    "    target=target.numpy()\n",
    "    target_data.append(target)\n",
    "\n",
    "n=np.array(target_data[0])\n",
    "target_1=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,157):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    target_1=torch.cat((target_1, y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_1=target_1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_array=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    output_n=output[n][0].data.numpy()\n",
    "    output_array.append(output_n)\n",
    "    \n",
    "output_array=np.array(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    digit=output_array[n][784:]\n",
    "    digits.append(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getdigit(outputarray):\n",
    "    results=[]\n",
    "    index=[]\n",
    "    for i in range(0,len(outputarray)):\n",
    "        for n in range(0, 10):\n",
    "            if outputarray[i][n]==1:\n",
    "                results.append(int(n))\n",
    "                index.append(int(i))\n",
    "        if all(outputarray[i][0:10]==0):\n",
    "            results.append(int(0))\n",
    "            index.append(int(i))\n",
    "   # results=np.array(results)\n",
    "    #index=np.array(index)\n",
    "    #total=np.stack((index, results), axis=0)\n",
    "    total=list(zip(index,results))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_digits=getdigit(digits)\n",
    "#output_digits=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification=[]\n",
    "for i, x in enumerate(output_digits):\n",
    "    classification.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification=np.array(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class=pd.DataFrame(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_class=df_class.drop_duplicates(subset=0, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_class=final_class.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct=0\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    if target_1[i]==final_class[1][i]:\n",
    "        correct+=1\n",
    "        \n",
    "accuracy=correct/len(target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7683"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7683"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
