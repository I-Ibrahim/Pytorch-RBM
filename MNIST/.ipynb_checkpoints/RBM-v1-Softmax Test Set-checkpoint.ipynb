{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_vis=784,\n",
    "                 n_hin=625,\n",
    "                 k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "    def sample_from_p(self,p):\n",
    "        return F.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "    def v_to_h(self,v):\n",
    "        p_h = F.sigmoid(F.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_from_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "    def h_to_v(self,h):\n",
    "        p_v = F.sigmoid(F.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_from_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "    def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_, h_\n",
    "    \n",
    "    def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = F.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding target at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(train_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "        target=target.view(-1)\n",
    "        target=target.numpy()\n",
    "        target_data.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=np.array(target_data[0])\n",
    "x=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,938):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    x=torch.cat((x, y),0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,938):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=x.numpy()\n",
    "\n",
    "target_array=np.zeros((60000,10))\n",
    "\n",
    "count=0\n",
    "for n in x:\n",
    "    target_array[count][n]=1\n",
    "    count+=1\n",
    "\n",
    "target_array=torch.Tensor(target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_training_data=torch.cat((full_input, target_array), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "          ...             â‹±             ...          \n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  1.0000  0.0000\n",
       "[torch.FloatTensor of size 60000x794]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = RBM(k=10, n_vis=794)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: Variable containing:\n",
      " 0.1183\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-2.08445396953\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  8.6379\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-5.42782859843\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.9104\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-3.49897132637\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.5233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-2.2799940893\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.2727\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-1.47360877624\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.0903\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-0.875041200359\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  6.9512\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-0.537825479579\n",
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  6.8513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "-0.206511018116\n"
     ]
    }
   ],
   "source": [
    "batch_size_=64\n",
    "\n",
    "for epoch in range(8):\n",
    "    loss_ = []\n",
    "    reconstruction_error=0\n",
    "    s=0\n",
    "    for n in range(0, len(final_training_data)- batch_size_, batch_size_):\n",
    "        sample_data=final_training_data[n:n+batch_size_]\n",
    "        sample_data=Variable(sample_data)\n",
    "        sample_data = sample_data.bernoulli()\n",
    "        v,v1,h1 = rbm(sample_data)\n",
    "        \n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data[0])\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        reconstruction_error+=torch.mean(torch.abs(v-v1))\n",
    "        s+=1\n",
    "    print (' loss: ' + str(reconstruction_error/s))     \n",
    "    print (np.mean(loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,157):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dummy=np.zeros((len(full_input), 10))\n",
    "test_dummy=torch.Tensor(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set=torch.cat((full_input, test_dummy), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.1681\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output=[]\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "s=0\n",
    "for n in range(0,len(test_set)):\n",
    "    sample_data=Variable(test_set)\n",
    "    sample_data = sample_data[n:n+1]\n",
    "\n",
    "    v,v1,h1 = rbm(sample_data)\n",
    "    test_loss+=torch.mean(torch.abs(v-v1))\n",
    "    s+=1\n",
    "    output.append(v1)\n",
    "print (' loss: ' + str(test_loss/s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "    target=target.view(-1)\n",
    "    target=target.numpy()\n",
    "    target_data.append(target)\n",
    "\n",
    "n=np.array(target_data[0])\n",
    "target_1=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,157):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    target_1=torch.cat((target_1, y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_1=target_1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_array=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    output_n=output[n][0].data.numpy()\n",
    "    output_array.append(output_n)\n",
    "    \n",
    "output_array=np.array(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    digit=output_array[n][784:]\n",
    "    digits.append(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdigit(outputarray):\n",
    "    results=[]\n",
    "    index=[]\n",
    "    for i in range(0,len(outputarray)):\n",
    "        for n in range(0, 10):\n",
    "            if outputarray[i][n]==1:\n",
    "                results.append(int(n))\n",
    "                index.append(int(i))\n",
    "        if all(outputarray[i][0:10]==0):\n",
    "            results.append(int(0))\n",
    "            index.append(int(i))\n",
    "   # results=np.array(results)\n",
    "    #index=np.array(index)\n",
    "    #total=np.stack((index, results), axis=0)\n",
    "    total=list(zip(index,results))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_digits=getdigit(digits)\n",
    "#output_digits=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=[]\n",
    "for i, x in enumerate(output_digits):\n",
    "    classification.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=np.array(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class=pd.DataFrame(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class=df_class.drop_duplicates(subset=0, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class=final_class.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    if target_1[i]==final_class[1][i]:\n",
    "        correct+=1\n",
    "        \n",
    "accuracy=correct/len(target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
