{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Function\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Softmax Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_data=[]\n",
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(train_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "        target=target.view(-1)\n",
    "        target=target.numpy()\n",
    "        target_data.append(target)\n",
    "\n",
    "n=np.array(target_data[0])\n",
    "x=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,938):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    x=torch.cat((x, y),0)\n",
    "    \n",
    "\n",
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,938):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)\n",
    "\n",
    "x=x.numpy()\n",
    "\n",
    "target_array=np.zeros((60000,10))\n",
    "\n",
    "count=0\n",
    "for n in x:\n",
    "    target_array[count][n]=1\n",
    "    count+=1\n",
    "\n",
    "target_array=torch.Tensor(target_array)\n",
    "\n",
    "final_training_data=torch.cat((full_input, target_array), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_vis=794,\n",
    "                 n_hin=625,\n",
    "                 k=1):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "    def sample_p(self,p):\n",
    "        return Function.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "    def v_to_h(self,v):\n",
    "        p_h = Function.sigmoid(Function.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "    def h_to_v(self,h):\n",
    "        p_v = Function.sigmoid(Function.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "    def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        \n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_, h_\n",
    "    \n",
    "    def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = Function.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = RBM(k=10)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - reconstructions error:  0.1368513891 - free energy loss: 2.49504118668\n",
      "Epoch: 2 - reconstructions error:  0.100497438152 - free energy loss: -3.63298811449\n",
      "Epoch: 3 - reconstructions error:  0.0922493379933 - free energy loss: -2.39830875295\n",
      "Epoch: 4 - reconstructions error:  0.0880711981937 - free energy loss: -1.4871570176\n",
      "Epoch: 5 - reconstructions error:  0.0852940822996 - free energy loss: -0.783779115789\n",
      "Epoch: 6 - reconstructions error:  0.0832473445473 - free energy loss: -0.315411025203\n",
      "Epoch: 7 - reconstructions error:  0.0817952517384 - free energy loss: 0.101648906761\n",
      "Epoch: 8 - reconstructions error:  0.0805686616847 - free energy loss: 0.312100047108\n",
      "Epoch: 9 - reconstructions error:  0.0794975663453 - free energy loss: 0.540013886312\n",
      "Epoch: 10 - reconstructions error:  0.0787476058195 - free energy loss: 0.73954634529\n"
     ]
    }
   ],
   "source": [
    "batch_size_=64\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_ = []\n",
    "    reconstruction_error=0\n",
    "    s=0\n",
    "    for n in range(0, len(full_input)- batch_size_, batch_size_):\n",
    "        sample_data=final_training_data[n:n+batch_size_]\n",
    "        sample_data=Variable(sample_data)\n",
    "        sample_data = sample_data.bernoulli()\n",
    "        \n",
    "        \n",
    "        v,v1,h1 = rbm(sample_data)\n",
    "        \n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data[0])\n",
    "        \n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        \n",
    "        reconstruction_error+=torch.mean(torch.abs(v-v1))\n",
    "        s+=1\n",
    "        \n",
    "    print ('Epoch: ' + str(epoch+1) +  \n",
    "           ' - reconstructions error:  ' + str(reconstruction_error.data.numpy()[0]/s) + \n",
    "           ' - free energy loss: ' + str(np.mean(loss_)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "        data =data.view(-1,784)\n",
    "        data=data.numpy()\n",
    "        input_data.append(data)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_input=np.array(input_data[0])\n",
    "full_input=torch.Tensor(full_input)\n",
    "\n",
    "for i in range(1,157):\n",
    "    intermed=np.array(input_data[i])\n",
    "    intermed=torch.Tensor(intermed)\n",
    "    \n",
    "    full_input=torch.cat((full_input, intermed),0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dummy=np.zeros((len(full_input), 10))\n",
    "test_dummy=torch.Tensor(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set=torch.cat((full_input, test_dummy), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructions error:  0.0837298339844 - free energy loss: 16.8534106355\n",
      "--- training time is 68.39816904067993 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "output=[]\n",
    "target_output=[]\n",
    "\n",
    "test_loss = 0\n",
    "s=0\n",
    "for n in range(0,len(test_set)):\n",
    "    sample_data=Variable(test_set)\n",
    "    sample_data = sample_data[n:n+1]\n",
    "\n",
    "    v,v1,h1 = rbm(sample_data)\n",
    "    test_loss+=torch.mean(torch.abs(v-v1))\n",
    "    s+=1\n",
    "    \n",
    "    loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "    loss_.append(loss.data[0])\n",
    "    \n",
    "    output.append(v1)\n",
    "    target_output.append(v)\n",
    "    \n",
    "    \n",
    "print ('Reconstructions error:  ' + str(test_loss.data.numpy()[0]/s)+ \n",
    "          ' - free energy loss: ' + str(np.mean(loss_)))  \n",
    "print(\"--- training time is %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange output array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data=[]\n",
    "\n",
    "for _, (data,target) in enumerate(test_loader):\n",
    "    target=target.view(-1)\n",
    "    target=target.numpy()\n",
    "    target_data.append(target)\n",
    "\n",
    "n=np.array(target_data[0])\n",
    "target_1=torch.from_numpy(n)\n",
    "\n",
    "for i in range(1,157):\n",
    "    y=np.array(target_data[i])\n",
    "    y=torch.from_numpy(y)\n",
    "    target_1=torch.cat((target_1, y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_1=target_1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_array=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    output_n=output[n][0].data.numpy()\n",
    "    output_array.append(output_n)\n",
    "    \n",
    "output_array=np.array(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits=[]\n",
    "\n",
    "for n in range(0, 10000):\n",
    "    digit=output_array[n][784:]\n",
    "    digits.append(digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getdigit(outputarray):\n",
    "    results=[]\n",
    "    index=[]\n",
    "    for i in range(0,len(outputarray)):\n",
    "        for n in range(0, 10):\n",
    "            if outputarray[i][n]==1:\n",
    "                results.append(int(n))\n",
    "                index.append(int(i))\n",
    "        if all(outputarray[i][0:10]==0):\n",
    "            results.append(int(0))\n",
    "            index.append(int(i))\n",
    "   # results=np.array(results)\n",
    "    #index=np.array(index)\n",
    "    #total=np.stack((index, results), axis=0)\n",
    "    total=list(zip(index,results))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_digits=getdigit(digits)\n",
    "#output_digits=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification=[]\n",
    "for i, x in enumerate(output_digits):\n",
    "    classification.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification=np.array(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy is 0.8596 \n"
     ]
    }
   ],
   "source": [
    "df_class=pd.DataFrame(classification)\n",
    "\n",
    "final_class=df_class.drop_duplicates(subset=0, keep='first')\n",
    "\n",
    "final_class=final_class.reset_index()\n",
    "\n",
    "correct=0\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    if target_1[i]==final_class[1][i]:\n",
    "        correct+=1\n",
    "        \n",
    "accuracy=correct/len(target_1)\n",
    "\n",
    "print ( 'classification accuracy is %s ' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=rbm.W\n",
    "weights=weights.data.numpy()\n",
    "\n",
    "\n",
    "x=weights.reshape(496250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savedweights=weights\n",
    "x=savedweights.reshape(496250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.064853\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "\n",
    "positive=[]\n",
    "negative=[]\n",
    "for n in x:\n",
    "    if n>0:\n",
    "        positive.append(n)\n",
    "    elif n<0:\n",
    "        negative.append(n)\n",
    "\n",
    "m=[]\n",
    "for n in negative:\n",
    "    if n>-0.5:\n",
    "        m.append(n)\n",
    "\n",
    "m=np.array(m)\n",
    "print (np.median(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune\n",
    "\n",
    "\n",
    "i = []\n",
    "\n",
    "for w in x:\n",
    "    if w < 0.03 and w > -0.03:\n",
    "        w=0\n",
    "        \n",
    "    else:\n",
    "        w=w\n",
    "    i.append(w)\n",
    "\n",
    "i=np.array(i).reshape(625, 794)\n",
    "\n",
    "w=torch.Tensor(i)\n",
    "\n",
    "\n",
    "o=torch.nn.Parameter(w)\n",
    "rbm.W=o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quantise\n",
    "\n",
    "q=[]\n",
    "\n",
    "for w in x:\n",
    "    if w > 0.15:\n",
    "        w=float(1)\n",
    "    elif w<-0.15:\n",
    "        w=float(-1)\n",
    "    else:\n",
    "        w=float(0)\n",
    "    q.append(w)\n",
    "    \n",
    "q=np.array(q).reshape(625, 784)\n",
    "w=torch.Tensor(q)\n",
    "w=torch.nn.Parameter(w)\n",
    "rbm.W=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean quantise\n",
    "\n",
    "q=[]\n",
    "\n",
    "for w in x:\n",
    "    if w >= 0.3:\n",
    "        w=float(1)\n",
    "    elif w > 0.02 and w<0.3:\n",
    "        w=float(0.07)\n",
    "    elif w<=-0.3:\n",
    "        w=float(-1)\n",
    "    elif w<-0.02 and w>-0.3:\n",
    "        w=float(-0.07)\n",
    "    else:\n",
    "        w=float(0)\n",
    "    q.append(w)\n",
    "    \n",
    "q=np.array(q).reshape(1000, 784)\n",
    "w=torch.Tensor(q)\n",
    "w=torch.nn.Parameter(w)\n",
    "rbm.W=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "output=[]\n",
    "target_output=[]\n",
    "\n",
    "test_loss = 0\n",
    "s=0\n",
    "for n in range(0,len(test_set)):\n",
    "    sample_data=Variable(test_set)\n",
    "    sample_data = sample_data[n:n+1]\n",
    "\n",
    "    v,v1,h1 = rbm(sample_data)\n",
    "    test_loss+=torch.mean(torch.abs(v-v1))\n",
    "    s+=1\n",
    "    \n",
    "    loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "    loss_.append(loss.data[0])\n",
    "    \n",
    "    output.append(v1)\n",
    "    target_output.append(v)\n",
    "    \n",
    "    \n",
    "print ('Reconstructions error:  ' + str(test_loss.data.numpy()[0]/s)+ \n",
    "          ' - free energy loss: ' + str(np.mean(loss_)))  \n",
    "print(\"--- training time is %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructions error:  0.0838052612305 - free energy loss: 17.6841711024\n",
      "--- training time is 75.55067801475525 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "output=[]\n",
    "target_output=[]\n",
    "\n",
    "test_loss = 0\n",
    "s=0\n",
    "for n in range(0,len(test_set)):\n",
    "    sample_data=Variable(test_set)\n",
    "    sample_data = sample_data[n:n+1]\n",
    "\n",
    "    v,v1,h1 = rbm(sample_data)\n",
    "    test_loss+=torch.mean(torch.abs(v-v1))\n",
    "    s+=1\n",
    "    \n",
    "    loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "    loss_.append(loss.data[0])\n",
    "    \n",
    "    output.append(v1)\n",
    "    target_output.append(v)\n",
    "    \n",
    "    \n",
    "print ('Reconstructions error:  ' + str(test_loss.data.numpy()[0]/s)+ \n",
    "          ' - free energy loss: ' + str(np.mean(loss_)))  \n",
    "print(\"--- training time is %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
